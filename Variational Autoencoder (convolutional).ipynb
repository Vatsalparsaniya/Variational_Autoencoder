{"cells":[{"metadata":{},"cell_type":"markdown","source":["1.  [Introduction](#1)\n","2.  [Applications](#2)\n","3.  [Architecture](#3)\n","4.  [Properties of Autoencoder](#4)\n","5.  [Types of Autoencoder](#5)\n","6.  [Variational Autoencoder (convolutional)](#vae)\n","    * [Encoder implementation](#7)\n","    * [Latent space implementation](#8)\n","    * [Decoder implementation](#9)\n","    * [Loss Function](#10)\n","    * [Model layers plot](#11)\n","    * [Model training](#12)\n","    * [Model prediction](#13)\n","    * [Visualize  prediction](#14)\n","    * [Encoded dimension visualization ](#15)\n","    * [Decoder/Generator Model](#16)\n","    * [Remove Noise](#17)"]},{"metadata":{},"cell_type":"markdown","source":["# <font color='red'>Please!!! Upvote this kernel if you find it useful.</font>"]},{"metadata":{},"cell_type":"markdown","source":["<a id='1'></a>\n","# Autoencoder\n","* neural network with unsupervised machine-learning algorithm apply back-prop to set target value to the input\n","* auto-encoder prefers over PCA because it can learn non-linear transformations with non-linear activation functions. more efficient to learn several layer with auto-encoder then one huge transformation with PCA."]},{"metadata":{},"cell_type":"markdown","source":["<a id='2'></a>\n","# Autoencoder Applications\n","* Image coloring (Black-white images -> colored)\n","* Feature variation (Extract required feature)\n","* Dimensionality Reduction\n","* Denosing image (Remove Noise)\n","* Remove watermark"]},{"metadata":{},"cell_type":"markdown","source":["<a id='3'></a>\n","# Autoencoder Architecture\n","* **Encoder** : part of NN compress the input into latent space representation\n","* **code** : part of NN represents compressed input \n","* **Decoder** : Decode the encoded data to original dimension"]},{"metadata":{},"cell_type":"markdown","source":["<a id='4'></a>\n","# Properties of Autoencoder\n","1. **Data-specific**: Autoencoders are only able to meaningfully compress data similar to what they have been trained on.\n","2. **Lossy**: de-compressed output will be degrad compared to the original input\n","3. **Unsupervised**: Autoencoders are considered an unsupervised learning technique since they donâ€™t need explicit labels to train on. But to be more precise they are **self-supervised** because they generate their own labels from the training data."]},{"metadata":{},"cell_type":"markdown","source":["<a id='5'></a>\n","# Types of Autoencoder\n","1.  **Denoising** autoencoder.\n","2.  **Sparse** Autoencoder.\n","3.  **Deep** Autoencoder.\n","4.  **Contractive** Autoencoder.\n","5.  **Undercomplete** Autoencoder.\n","6.  **Convolutional** Autoencoder.\n","7.  **Variational** Autoencoder."]},{"metadata":{},"cell_type":"markdown","source":["# Variational Autoencoder (convolutional)<a id=\"vae\"></a>\n"]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import random\n","\n","from scipy.stats import norm\n","\n","import keras\n","from keras import backend as k\n","k.clear_session()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# set parameter\n","image_shape = (28,28,1)\n","batch_size = 64\n","latent_dim = 10\n","epoch = 30"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# import minist dataset\n","(x_train, y_train), (x_test,y_test) = keras.datasets.mnist.load_data()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# change datatype and reshape data\n","x_train = x_train.astype('float32') / 255.\n","x_train = x_train.reshape((x_train.shape[0],) + image_shape)\n","x_test = x_test.astype('float32') / 255.\n","x_test = x_test.reshape((x_test.shape[0],) + image_shape)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# function to fatch 10 images of labeld 0 to 9\n","def get_images_1_to_10(x_train,y_train):\n","    selected_x,selected_y = [],[]\n","    for i in range(10):\n","        number_index = np.where(y_train == i)[0]\n","        random_index = np.random.choice(len(number_index),1,replace=False)\n","        select_index = number_index[random_index]\n","        selected_x.append(x_train[select_index[0]])\n","        selected_y.append(y_train[select_index][0])\n","    return np.array(selected_x,dtype=\"float32\").reshape((len(selected_x),)+image_shape),np.array(selected_y,dtype=\"float32\")"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# select random 10 image of labeled 0 to 9\n","selected_x,selected_y =  get_images_1_to_10(x_train,y_train)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# function for plot images\n","def plot_image(selected_x,selected_y,title=None,save=None):\n","    ncols = selected_x.shape[0]\n","    fig,ax  = plt.subplots(nrows=1, ncols=ncols,figsize=(20,3))\n","    for x,y,ax_i in zip(selected_x,selected_y,ax):\n","        ax_i.imshow(x.reshape((28,28)))\n","        ax_i.axis(\"off\")\n","        ax_i.set_title(int(y))\n","    if title:\n","        fig.suptitle(title)\n","    if save:\n","        fig.savefig(str(save)+\".png\")\n","    plt.show()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# plot selected images\n","plot_image(selected_x,selected_y,title=\"original images\",save=\"original_images\")"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["<a id='7'></a>\n","## Encoder implementation"]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Input layer\n","# input shape = (None,28,28,1)\n","encoder_input = keras.Input(shape=image_shape)\n","\n","# convolutional layer 1\n","# input shape = (None,28,28,1)\n","# output shape = (None,28,28,32)\n","conv_1 = keras.layers.Conv2D(filters=32,\n","                             kernel_size=3,\n","                             padding=\"same\",\n","                             activation=\"relu\",\n","                            )(encoder_input)\n","\n","# convolutional layer 2\n","# input shape = (None,28,28,32)\n","# output shape = (None,28,28,64)\n","conv_2 = keras.layers.Conv2D(filters=64,\n","                             kernel_size=3,\n","                             padding=\"same\",\n","                             activation=\"relu\",\n","                            )(conv_1)\n","\n","# convolutional layer 3\n","# input shape = (None,28,28,64)\n","# output shape = (None,28,28,64)\n","conv_3 = keras.layers.Conv2D(filters=64,\n","                             kernel_size=3,\n","                             padding=\"same\",\n","                             activation=\"relu\",\n","                            )(conv_2)\n","\n","# Flatten layer\n","# input shape = (None,28,28,64)\n","# output shape = (None,50176)\n","flatten = keras.layers.Flatten()(conv_3)\n","\n","# Dense layer 1\n","# input shape = (None,50176)\n","# output shape = (None,128)\n","encoder_output = keras.layers.Dense(128,activation=\"relu\")(flatten)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["<a id='8'></a>\n","## Latent space implementation"]},{"metadata":{"trusted":true},"cell_type":"code","source":["# latent mean and (log)variance\n","\n","# Dense layer 2\n","# input shape = (None,128)\n","# output shape = (None,latent_dim)\n","z_mu = keras.layers.Dense(latent_dim)(encoder_output)\n","\n","# Dense layer 3\n","# input shape = (None,128)\n","# output shape = (None,latent_dim)\n","z_log_sigma = keras.layers.Dense(latent_dim)(encoder_output)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# sampling function for latent layer\n","def sampling(args):\n","    z_mu, z_log_sigma = args\n","\n","    # epsilon is simple normal distribution\n","    epsilon = k.random_normal(shape=(k.shape(z_mu)[0], latent_dim),mean=0., stddev=1.)\n","    return z_mu + k.exp(z_log_sigma) * epsilon\n","\n","z = keras.layers.Lambda(sampling,output_shape=(latent_dim,))([z_mu, z_log_sigma])"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["<a id='9'></a>\n","## Decoder implementation"]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Dense layer 4\n","# input shape = (None,latent_dim)\n","# output shape = (None,128)\n","dense_2 = keras.layers.Dense(128,activation=\"relu\")\n","\n","# Dense layer 4\n","# input shape = (None,128)\n","# output shape = (None,50176)\n","dense_3 = keras.layers.Dense(np.prod(k.int_shape(conv_3)[1:]),\n","                             activation=\"relu\"\n","                            )\n","\n","# Reshape layer \n","# input shape = (None,128)\n","# output shape = (None,28,28,64)\n","reshape = keras.layers.Reshape(k.int_shape(conv_3)[1:])\n","\n","# Deconvolutional layer 1\n","# input shape = (None,28,28,64)\n","# output shape = (None,28,28,64)\n","conv_4 = keras.layers.Conv2DTranspose(filters=64,\n","                                      kernel_size=3,\n","                                      padding=\"same\",\n","                                      activation=\"relu\"\n","                                     )\n","# Deconvolutional layer 2\n","# input shape = (None,28,28,64)\n","# output shape = (None,28,28,64)\n","conv_5 = keras.layers.Conv2DTranspose(filters=64,\n","                                      kernel_size=3,\n","                                      padding=\"same\",\n","                                      activation=\"relu\"\n","                                     )\n","\n","# Deconvolutional layer 3\n","# input shape = (None,28,28,64)\n","# output shape = (None,28,28,32)\n","conv_6 = keras.layers.Conv2DTranspose(filters=32,\n","                                      kernel_size=3,\n","                                      padding=\"same\",\n","                                      activation=\"relu\"\n","                                     )\n","\n","# convolutional layer 4\n","# input shape = (None,28,28,32)\n","# output shape = (None,28,28,1)\n","decoder_output = keras.layers.Conv2D(filters=1,\n","                                     kernel_size=3,\n","                                     padding=\"same\",\n","                                     activation=\"sigmoid\"\n","                                    )\n","\n","_dense_2 = dense_2(z)\n","_dense_3 = dense_3(_dense_2)\n","_reshape = reshape(_dense_3)\n","_conv_4 = conv_4(_reshape)\n","_conv_5 = conv_5(_conv_4)\n","_conv_6 = conv_6(_conv_5)\n","_decoder_output = decoder_output(_conv_6)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## Loss Function<a id='10'></a>"]},{"metadata":{"trusted":true},"cell_type":"code","source":["def vae_loss(x, z_decoded):\n","        x = k.flatten(x)\n","        z_decoded = k.flatten(z_decoded)\n","        # Reconstruction loss\n","        Reconstruction_loss = 786*keras.metrics.binary_crossentropy(x, z_decoded)\n","        # KL divergence\n","        kl_loss = -0.5 * k.mean(1 + z_log_sigma - k.square(z_mu) - k.exp(z_log_sigma), axis=-1)\n","        return Reconstruction_loss + kl_loss"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## Model compile and summary"]},{"metadata":{"trusted":true},"cell_type":"code","source":["variational_encoder = keras.Model(encoder_input,_decoder_output)\n","variational_encoder.compile(optimizer='rmsprop',loss=vae_loss)\n","variational_encoder.summary()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## Model plot<a id='11'></a>"]},{"metadata":{"trusted":true},"cell_type":"code","source":["keras.utils.plot_model(variational_encoder,to_file=\"variational_encoder_L{}_E_{}.png\".format(latent_dim,epoch),show_shapes=True)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## Model training<a id='12'></a>"]},{"metadata":{"trusted":true},"cell_type":"code","source":["variational_encoder.fit(x=x_train,y=x_train,\n","                        shuffle=True,\n","                        epochs=epoch,\n","                        batch_size=batch_size,\n","                        validation_data=(x_test,x_test))"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Model weights save\n","variational_encoder.save_weights('vae_L2_E10.h5')"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## Model prediction<a id='13'></a>"]},{"metadata":{"trusted":true},"cell_type":"code","source":["pred = variational_encoder.predict(selected_x)"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## Visualize prediction<a id='14'></a>"]},{"metadata":{"trusted":true},"cell_type":"code","source":["plot_image(selected_x,selected_y)\n","plot_image(pred,selected_y,title=\"prediction_from_original_images\",save=\"prediction_from_original_images\")"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## Encoded dimension visualization <a id='15'></a>"]},{"metadata":{"trusted":true},"cell_type":"code","source":["encoder = keras.Model(encoder_input,z_mu)\n","x_test_encoded = encoder.predict(x_test, batch_size=batch_size)\n","plt.figure(figsize=(6, 6))\n","plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test)\n","plt.colorbar()\n","plt.title(\"Encoded_dimension_visualization_L{}_E{}\".format(latent_dim,epoch))\n","plt.savefig(\"Encoded_dimension_visualization_L{}_E{}.png\".format(latent_dim,epoch))\n","plt.show()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["## Decoder/Generator Model<a id='16'></a>"]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Generator Model\n","decoder_input = keras.layers.Input(shape=(latent_dim,))\n","_dense_2 = dense_2(decoder_input)\n","_dense_3 = dense_3(_dense_2)\n","_reshape = reshape(_dense_3)\n","_conv_4 = conv_4(_reshape)\n","_conv_5 = conv_5(_conv_4)\n","_conv_6 = conv_6(_conv_5)\n","_decoder_output = decoder_output(_conv_6)\n","\n","decoder = keras.Model(decoder_input,_decoder_output)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["digit_size = 28\n","n = 10  # figure with 10x10 digits\n","figure = np.zeros((digit_size * n, digit_size * n))\n","\n","for i in range(n):\n","    for j in range(n):\n","        z_sample = np.random.normal(size=latent_dim).reshape(1, latent_dim)\n","        x_decoded = decoder.predict(z_sample, batch_size=1)\n","        digit = x_decoded[0].reshape(digit_size, digit_size)\n","        \n","        x = i * digit_size\n","        y = j * digit_size\n","        figure[x:x + digit_size, y:y + digit_size] = digit\n","\n","plt.figure(figsize=(14, 14))\n","plt.axis(\"off\")\n","plt.imshow(figure, cmap='Greys_r')\n","plt.title(\"generated_images_L{}_E_{}\".format(latent_dim,epoch))\n","plt.savefig(\"generated_images_L{}_E_{}.png\".format(latent_dim,epoch))\n","plt.show()"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["# Remove Noise<a id=\"17\"></a>"]},{"metadata":{"trusted":true},"cell_type":"code","source":["def add_noise(x, noise_factor=0.1):\n","    x = x + np.random.randn(*x.shape) * noise_factor\n","    x = x.clip(0., 1.)\n","    return x"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["selected_x_noisy = add_noise(selected_x)\n","pred_noise_remove = variational_encoder.predict(selected_x_noisy)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# selected original images\n","plot_image(selected_x,selected_y,title=\"selected original images\")\n","# add noise to  original images\n","plot_image(selected_x_noisy,selected_y,title=\"Noisy_images\",save=\"Noisy_images\")\n","# predicted images from noisy image\n","plot_image(pred_noise_remove,selected_y,title=\"prediction_from_noisy_image\",save=\"prediction_from_noisy_image\")"],"execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":["# <font color='red'>Please!!! Upvote this kernel if you find it useful.</font>"]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}